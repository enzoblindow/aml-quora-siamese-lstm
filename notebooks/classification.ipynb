{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6c5c9fee474fbfb085c5bd490f53bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# init logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# init tqdm\n",
    "try:\n",
    "    if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "        tqdm_notebook().pandas()\n",
    "    else:\n",
    "        tqdm.pandas()\n",
    "except NameError:\n",
    "    tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dfs = [\n",
    "    {\n",
    "        'df': '../data/{}_features.csv',\n",
    "        'cols': [\n",
    "            'last_char',\n",
    "             'avg_shared_words',\n",
    "             'word_count_diff',\n",
    "             'levenshtein',\n",
    "             'shared_words_pcnt',\n",
    "             'avg_shared_trigrams',\n",
    "             'shared_bigram_pcnt',\n",
    "             'shared_trigram_pcnt',\n",
    "             'avg_shared_quadgrams',\n",
    "             'shared_quadgram_pcnt',\n",
    "             'shared_entities',\n",
    "             'non_shared_entities',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'df': '../data/{}_lstm_output.csv',\n",
    "        'cols': [\n",
    "            'nn_out'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'df': '../data/tfidf_{}_features.csv',\n",
    "        'cols': [\n",
    "            'tfidf_word_match_share'\n",
    "        ]\n",
    "    },\n",
    "#     {\n",
    "#         'df': '../data/topic_modelling_output.csv',\n",
    "#         'cols': []\n",
    "#     },\n",
    "    {\n",
    "        'df': '../data/{}_with_sim_and_ents_long.csv',\n",
    "        'cols': [\n",
    "            'CARDINAL_1','DATE_1','EVENT_1','FAC_1','GPE_1','LANGUAGE_1','LAW_1','LOC_1','MONEY_1','NORP_1',\n",
    "            'ORDINAL_1','ORG_1','PERCENT_1','PERSON_1','PRODUCT_1','QUANTITY_1','TIME_1','WORK_OF_ART_1',\n",
    "            'CARDINAL_2','DATE_2','EVENT_2','FAC_2','GPE_2','LANGUAGE_2','LAW_2','LOC_2','MONEY_2','NORP_2',\n",
    "            'ORDINAL_2','ORG_2','PERCENT_2','PERSON_2','PRODUCT_2','QUANTITY_2','TIME_2','WORK_OF_ART_2',\n",
    "        ]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df(df, merge_col='id', _set='train'):\n",
    "    \"\"\"\n",
    "    Creates the dataframe for either train or test set identically.\n",
    "    \n",
    "    Parameter\n",
    "        df: base dataframe containing the ids and questions\n",
    "        merge_col: specify the column name how to merge the dataframe together\n",
    "        _set: pass either 'test' or 'train'\n",
    "        \n",
    "    Returns\n",
    "        df: fully merged dataframe\n",
    "    \"\"\"\n",
    "    for _df in _dfs:\n",
    "        path = _df['df'].format(_set)\n",
    "        df = df.merge(pd.read_csv(path).loc[:,[merge_col] + _df['cols']], on=merge_col, how='left')\n",
    "        logging.info('Merged in {}'.format(path))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_set(df, preds_array, file_path):\n",
    "    \"\"\"\n",
    "    Builds the csv in the format that can be uploaded to kaggle.\n",
    "    \n",
    "    Parameter\n",
    "        df: test dataframe containing the test ids and that was used to make the predictions\n",
    "        preds_array: the predicition array that was return by the model\n",
    "        file_path: specify the path and file name to store the output csv\n",
    "    \"\"\"\n",
    "    pd.DataFrame({\"test_id\": df['test_id'], \"is_duplicate\": preds_array}).to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train_data.csv')\n",
    "df_train = df_train.drop(['is_duplicate'], axis=1).merge(pd.read_csv('../data/train_labels.csv'), on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Merged in ../data/train_features.csv\n",
      "INFO:root:Merged in ../data/train_lstm_output.csv\n",
      "INFO:root:Merged in ../data/tfidf_train_features.csv\n",
      "INFO:root:Merged in ../data/train_with_sim_and_ents_long.csv\n"
     ]
    }
   ],
   "source": [
    "df_train = build_df(df_train, merge_col='id', _set='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Merged in ../data/test_features.csv\n",
      "INFO:root:Merged in ../data/test_lstm_output.csv\n",
      "INFO:root:Merged in ../data/tfidf_test_features.csv\n",
      "INFO:root:Merged in ../data/test_with_sim_and_ents_long.csv\n"
     ]
    }
   ],
   "source": [
    "df_test = build_df(df_test, merge_col='test_id', _set='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "1. Logistic Regression\n",
    "2. Stepwise Logistic Regression\n",
    "3. Decision Tree\n",
    "4. Random Forest\n",
    "5. SVM\n",
    "6. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_char</th>\n",
       "      <th>avg_shared_words</th>\n",
       "      <th>word_count_diff</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>shared_words_pcnt</th>\n",
       "      <th>avg_shared_trigrams</th>\n",
       "      <th>shared_bigram_pcnt</th>\n",
       "      <th>shared_trigram_pcnt</th>\n",
       "      <th>avg_shared_quadgrams</th>\n",
       "      <th>shared_quadgram_pcnt</th>\n",
       "      <th>...</th>\n",
       "      <th>MONEY_2</th>\n",
       "      <th>NORP_2</th>\n",
       "      <th>ORDINAL_2</th>\n",
       "      <th>ORG_2</th>\n",
       "      <th>PERCENT_2</th>\n",
       "      <th>PERSON_2</th>\n",
       "      <th>PRODUCT_2</th>\n",
       "      <th>QUANTITY_2</th>\n",
       "      <th>TIME_2</th>\n",
       "      <th>WORK_OF_ART_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.647482</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   last_char  avg_shared_words  word_count_diff  levenshtein  \\\n",
       "0        1.0              12.0              2.0     0.926829   \n",
       "1        1.0               4.0              5.0     0.647482   \n",
       "2        1.0               4.0              4.0     0.454545   \n",
       "3        1.0               0.0              2.0     0.069565   \n",
       "4        1.0               2.0              6.0     0.365217   \n",
       "\n",
       "   shared_words_pcnt  avg_shared_trigrams  shared_bigram_pcnt  \\\n",
       "0           0.923077                  9.0            0.833333   \n",
       "1           0.380952                  0.0            0.105263   \n",
       "2           0.333333                  0.0            0.090909   \n",
       "3           0.000000                  0.0            0.000000   \n",
       "4           0.200000                  0.0            0.000000   \n",
       "\n",
       "   shared_trigram_pcnt  avg_shared_quadgrams  shared_quadgram_pcnt  \\\n",
       "0             0.818182                   8.0                   0.8   \n",
       "1             0.000000                   0.0                   0.0   \n",
       "2             0.000000                   0.0                   0.0   \n",
       "3             0.000000                   0.0                   0.0   \n",
       "4             0.000000                   0.0                   0.0   \n",
       "\n",
       "       ...        MONEY_2  NORP_2  ORDINAL_2  ORG_2  PERCENT_2  PERSON_2  \\\n",
       "0      ...            0.0     0.0        0.0    0.0        0.0       0.0   \n",
       "1      ...            0.0     1.0        0.0    0.0        0.0       2.0   \n",
       "2      ...            0.0     0.0        0.0    1.0        0.0       0.0   \n",
       "3      ...            0.0     0.0        0.0    0.0        0.0       0.0   \n",
       "4      ...            0.0     0.0        0.0    0.0        0.0       0.0   \n",
       "\n",
       "   PRODUCT_2  QUANTITY_2  TIME_2  WORK_OF_ART_2  \n",
       "0        0.0         0.0     0.0            0.0  \n",
       "1        0.0         0.0     0.0            0.0  \n",
       "2        0.0         0.0     0.0            0.0  \n",
       "3        0.0         0.0     0.0            0.0  \n",
       "4        0.0         0.0     0.0            0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train['is_duplicate']\n",
    "x = df_train.drop(['id', 'question1', 'question2', 'is_duplicate'], axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 1\n"
     ]
    }
   ],
   "source": [
    "lm = sm.Logit(y, x)\n",
    "result = lm.fit()\n",
    "# print(result.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml-kaggle",
   "language": "python",
   "name": "aml-kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
